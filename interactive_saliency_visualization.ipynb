{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "processed-routine",
   "metadata": {},
   "source": [
    "<h1>Interactive Saliency map visualization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-circus",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-running",
   "metadata": {},
   "source": [
    "<p>This notebook help to visualize saliency maps from the npz files.</p>\n",
    "<p>Please check that the <b>requirements.txt</b> file is installed, that the ILSVRC2012 validation set <b>images</b> are in the \"images\" folder and .npz files in the <b>npz</b> folder (files available to download at <a href=https://polycam.ddns.net>https://polycam.ddns.net</a>, view <b>README</b> file for more informations). This notebook in addition requires <b>ipywidgets</b></p>\n",
    "<p>Run all cells at once, then you can use the interactive interface. If you change any parameter you should restart all cells</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-luther",
   "metadata": {},
   "source": [
    "<h2>Parameters</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-transformation",
   "metadata": {},
   "source": [
    "<h3>Saliency selection</h3>\n",
    "<p>If you generated npz of the saliency maps yourself from the script for only some of the above methods and models, or if you only extracted part of the npz zip files, please <b>comment the unused saliency methods</b> bellow.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['vgg16', 'resnet50']\n",
    "\n",
    "saliency_list = []\n",
    "saliency_list += ['pcamp4', 'pcamm4', 'pcampm4'] # Poly-CAM\n",
    "# Uncomment the following line if you want to add maps from the ablation study (Poly-CAM without LNorm)\n",
    "#saliency_list += ['pcampnolnorm4', 'pcammnolnorm4', 'pcampm4nolnorm']\n",
    "saliency_list.append('zoomcam') # Zoom-CAM\n",
    "saliency_list.append('layercamfusion4') # Layer-CAM\n",
    "saliency_list.append('gradcam') # Grad-CAM\n",
    "saliency_list.append('gradcampp') # Grad-CAM++\n",
    "saliency_list.append('smoothgradcampp') # SmoothGrad-CAM++\n",
    "saliency_list.append('scorecam') # Score-CAM\n",
    "saliency_list.append('sscam') # SS-CAM\n",
    "saliency_list.append('iscam') # IS-CAM\n",
    "saliency_list.append('ixg') # InputXGradient\n",
    "saliency_list.append('ig') # IntegratedGradient\n",
    "saliency_list.append('sg') # SmoothGrad\n",
    "saliency_list.append('occlusion') # Occlusion\n",
    "saliency_list.append('rise') # RISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-contributor",
   "metadata": {},
   "source": [
    "<h3>Other parameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = 'images.txt'\n",
    "labels_list = 'imagenet_validation_imagename_labels.txt'\n",
    "image_folder = 'images'\n",
    "npz_folder = './npz'\n",
    "results_folder = './results'\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-energy",
   "metadata": {},
   "source": [
    "<p>Please reload cells bellow if any parameter above is changed</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-manitoba",
   "metadata": {},
   "source": [
    "<h2>Code</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-fetish",
   "metadata": {},
   "source": [
    "<h3>Imports and load files</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from benchmarks.imagesDataset import ImagesDataset\n",
    "from benchmarks.utils import imagenet_labels, overlay\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Resize((input_size, input_size))\n",
    "                                ])\n",
    "\n",
    "\n",
    "dataset = ImagesDataset(image_list, labels_list, image_folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_file_dict = {}\n",
    "results_dict = {}\n",
    "for model in model_list:\n",
    "    saliency_file_dict[model] = {}\n",
    "    results_df = pd.read_csv(results_folder + \"/\" + model + \"_results.csv\", header = None, index_col=False)\n",
    "    results_dict[model] = dict(zip(results_df.iloc[:,0], results_df.iloc[:,1]))\n",
    "    for saliency in saliency_list:\n",
    "        saliency_npz = npz_folder + '/' + model + \"_\" + saliency + \".npz\"\n",
    "        saliency_file_dict[model][saliency] = np.load(saliency_npz)\n",
    "\n",
    "#saliency_npz = npz_folder + '/' + model.value + \"_\" + saliency.value + \".npz\"\n",
    "# get saliencies from file\n",
    "#saliency_file = np.load(saliency_npz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_overlayed(x=None):\n",
    "    with output_figure:\n",
    "        image, _, name = dataset[image_slider.value]\n",
    "        image = image.unsqueeze(0)\n",
    "        saliency_map = torch.tensor(saliency_file_dict[model.value][saliency.value][dataset[image_slider.value][2]])\n",
    "        sh, sw = saliency_map.shape[-2:]\n",
    "        if saliency.value in [\"ig\", \"ixg\"]:\n",
    "            saliency_map = torch.abs(saliency_map)\n",
    "        saliency_map = ( saliency_map - saliency_map.min() ) / ( saliency_map.max() - saliency_map.min() )\n",
    "        saliency_map = saliency_map.view(1, 1, sh, sw)\n",
    "        saliency_map = F.interpolate(saliency_map, dataset[image_slider.value][0].shape[-2:], mode='bilinear').type(torch.float32)\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        plt.imshow(overlay(dataset[image_slider.value][0], saliency_map[0].detach(), alpha=alpha_slider.value, colormap=\"turbo\" ))\n",
    "        plt.axis('off')\n",
    "        output_figure.clear_output()\n",
    "        fig.suptitle(\"saliency map for top class on \" + model.value + \":\\n \" + imagenet_labels[results_dict[model.value][name]], fontsize=24)\n",
    "        display(fig)\n",
    "        plt.close()\n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency = widgets.Dropdown(\n",
    "    options=saliency_list,\n",
    "    description='Saliency',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "model = widgets.Dropdown(\n",
    "    options=model_list,\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "image_slider = widgets.IntSlider(\n",
    "    value=1000,\n",
    "    min=0,\n",
    "    max=1999,\n",
    "    step=1,\n",
    "    description='Image selection:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True)\n",
    "\n",
    "alpha_slider = widgets.FloatSlider(\n",
    "    value=0.4,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description='Alpha:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.1f',)\n",
    "\n",
    "output_figure = widgets.Output()\n",
    "output_figure.layout.height = '500px'\n",
    "\n",
    "saliency.observe(display_overlayed, \"value\")\n",
    "model.observe(display_overlayed, \"value\")\n",
    "image_slider.observe(display_overlayed, \"value\")\n",
    "alpha_slider.observe(display_overlayed, \"value\")\n",
    "\n",
    "\n",
    "\n",
    "menu=widgets.VBox([saliency,\n",
    "                   model,\n",
    "                   image_slider,\n",
    "                   alpha_slider\n",
    "                  ])\n",
    "\n",
    "app_layout = widgets.Layout(display='flex',\n",
    "                flex_flow='row nowrap',\n",
    "                align_items='center',\n",
    "                border='none',\n",
    "                width='100%',\n",
    "                margin='5px 5px 5px 5px')\n",
    "\n",
    "app=widgets.HBox([menu, output_figure], layout=app_layout)\n",
    "\n",
    "display_overlayed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-statistics",
   "metadata": {},
   "source": [
    "<h2>Saliency overlay</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-rapid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sslXRay",
   "language": "python",
   "name": "sslxray"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
